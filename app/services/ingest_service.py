import json
from datetime import datetime

from sqlalchemy.orm import Session

from app.core.config import get_settings
from app.db import crud
from app.services.fetchers.irvine_crime import fetch_crime_rate_per_100k
from app.services.fetchers.overpass_osm import (
    fetch_grocery_density,
    fetch_night_activity_index,
    fetch_noise_proxy,
)
from app.services.fetchers.youtube import fetch_comments, search_video
from app.services.fetchers.zillow_zori import read_zori_rows
from app.services.scoring_service import compute_dimension_scores
from app.utils.time import is_expired


def ensure_metrics_fresh(db: Session, community_id: str, ttl_hours: int | None = None) -> None:
    settings = get_settings()
    effective_ttl = ttl_hours if ttl_hours is not None else settings.metrics_ttl_hours
    existing = crud.get_metrics(db, community_id)
    if existing and existing.updated_at and not is_expired(existing.updated_at, effective_ttl):
        return

    community = crud.get_community(db, community_id)
    if community is None:
        return

    # ZORI (local CSV for rent baseline)
    zori_rows = read_zori_rows()
    match = next((row for row in zori_rows if row.get("community_id") == community_id), None)
    grocery_density = None
    night_activity_index = None
    noise_avg_db = None
    noise_p90_db = None
    if community.center_lat is not None and community.center_lng is not None:
        grocery_density = fetch_grocery_density(community.center_lat, community.center_lng, radius_km=1.2)
        night_activity_index = fetch_night_activity_index(
            community.center_lat, community.center_lng, radius_km=1.5
        )
        noise_avg_db, noise_p90_db = fetch_noise_proxy(community.center_lat, community.center_lng)

    crime_rate = fetch_crime_rate_per_100k(community.city)

    youtube_video_id = None
    if existing and existing.youtube_video_id:
        youtube_video_id = existing.youtube_video_id
    else:
        # Search API
        query = f"{community.name} {community.city or 'Irvine'} tour review"
        youtube_video_id = search_video(query)

    if youtube_video_id:
        comments = fetch_comments(youtube_video_id, max_results=20)
        if comments:
            crud.save_youtube_comments(db, community_id, youtube_video_id, comments)

    payload: dict = {
        "updated_at": datetime.utcnow(),
        "grocery_density_per_km2": grocery_density,
        "crime_rate_per_100k": crime_rate,
        "youtube_video_id": youtube_video_id,
        "night_activity_index": None,
        "noise_avg_db": noise_avg_db,
        "noise_p90_db": noise_p90_db,
        "overall_confidence": 0.5,
        "details_json": "{}",
    }
    if match:
        payload.update(
            {
                "median_rent": _to_float(match.get("median_rent")),
                "rent_2b2b": _to_float(match.get("rent_2b2b")),
                "rent_1b1b": _to_float(match.get("rent_1b1b")),
                "avg_sqft": _to_float(match.get("avg_sqft")),
                "rent_trend_12m_pct": _to_float(match.get("rent_trend_12m_pct")),
                "overall_confidence": 0.7,
            }
        )
    if night_activity_index is not None:
        payload["night_activity_index"] = night_activity_index

    required_keys = [
        "median_rent",
        "grocery_density_per_km2",
        "crime_rate_per_100k",
        "rent_trend_12m_pct",
        "night_activity_index",
        "noise_avg_db",
    ]
    available = sum(1 for key in required_keys if payload.get(key) is not None)
    payload["overall_confidence"] = round(available / len(required_keys), 2)

    payload["details_json"] = json.dumps(
        {
            "sources": {
                "zori_csv": bool(match),
                "overpass_grocery": grocery_density is not None,
                "overpass_night_activity": night_activity_index is not None,
                "overpass_noise": noise_avg_db is not None,
                "irvine_crime": crime_rate is not None,
                "youtube_video": youtube_video_id is not None,
            }
        },
        ensure_ascii=True,
    )

    metrics = crud.upsert_metrics(db, community_id, payload)
    score_input = {
        "median_rent": metrics.median_rent,
        "commute_minutes": None,
        "grocery_density_per_km2": metrics.grocery_density_per_km2,
        "crime_rate_per_100k": metrics.crime_rate_per_100k,
        "rent_trend_12m_pct": metrics.rent_trend_12m_pct,
        "noise_avg_db": metrics.noise_avg_db,
        "night_activity_index": metrics.night_activity_index,
        "review_signal_score": None,
    }
    scores = compute_dimension_scores(score_input)
    for dimension, value in scores.items():
        crud.upsert_dimension_score(
            db=db,
            community_id=community_id,
            dimension=dimension,
            score_0_100=value,
            summary=f"{dimension} score auto-generated by ingest pipeline",
            details=score_input,
            data_origin="api",
        )


def ensure_reviews_fresh(db: Session, community_id: str) -> None:
    """
    Checks if we have reviews for this community. If not, fetches from YouTube
    using the video ID stored in metrics (or searches for one).
    """
    # 1. Check if we already have reviews
    existing_count = crud.get_reviews_count(db, community_id)
    if existing_count > 0:
        return

    # 2. Get community & metrics to find video ID
    community = crud.get_community(db, community_id)
    if not community:
        return

    metrics = crud.get_metrics(db, community_id)
    video_id = metrics.youtube_video_id if metrics else None

    # Helper function to try fetching comments for a given query
    def try_fetch_with_query(search_q: str) -> bool:
        print(f"SEARCHING YOUTUBE for '{search_q}'...")
        vid = search_video(search_q)
        if not vid:
            print(f"  -> No video found for '{search_q}'")
            return False
        
        print(f"  -> Found video ID: {vid}")
        # Try fetching comments
        comments = fetch_comments(vid, max_results=20)
        print(f"  -> Fetched {len(comments)} comments via YouTube API")
        
        if comments:
            # We found good stuff! Save video ID and comments
            metrics_payload = {"youtube_video_id": vid}
            crud.upsert_metrics(db, community_id, metrics_payload)
            crud.upsert_review_posts(db, community_id, "youtube", comments)
            return True
        return False

    # 3. If no video ID (or existing one yielded 0 comments before?), try to find one now
    # We'll just check if we have reviews. If not, we try searching fresh even if we have a video_id
    # (because maybe the old video_id was bad/empty)
    
    # Strategy: Try "apartment tour" first
    if try_fetch_with_query(f"{community.name} {community.city or ''} apartment tour"):
        return

    # Strategy: Try "living in" second
    if try_fetch_with_query(f"living in {community.name} {community.city or ''}"):
        return

    # Strategy: Try just the name + "review"
    if try_fetch_with_query(f"{community.name} {community.city or ''} review"):
        return


def _to_float(value: str | None) -> float | None:
    if value in (None, ""):
        return None
    try:
        return float(value)
    except ValueError:
        return None
