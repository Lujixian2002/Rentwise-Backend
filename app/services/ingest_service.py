import json
from datetime import datetime

from sqlalchemy.orm import Session

from app.core.config import get_settings
from app.db import crud
from app.services.fetchers.irvine_crime import fetch_crime_rate_per_100k
from app.services.fetchers.overpass_osm import (
    fetch_grocery_density,
    fetch_night_activity_index,
    fetch_noise_proxy,
)
from app.services.fetchers.zillow_zori import read_zori_rows
from app.services.scoring_service import compute_dimension_scores
from app.utils.time import is_expired


def ensure_metrics_fresh(db: Session, community_id: str, ttl_hours: int | None = None) -> None:
    settings = get_settings()
    effective_ttl = ttl_hours if ttl_hours is not None else settings.metrics_ttl_hours
    existing = crud.get_metrics(db, community_id)
    if existing and existing.updated_at and not is_expired(existing.updated_at, effective_ttl):
        return

    community = crud.get_community(db, community_id)
    if community is None:
        return

    # ZORI (local CSV for rent baseline)
    zori_rows = read_zori_rows()
    match = next((row for row in zori_rows if row.get("community_id") == community_id), None)
    grocery_density = None
    night_activity_index = None
    noise_avg_db = None
    noise_p90_db = None
    if community.center_lat is not None and community.center_lng is not None:
        grocery_density = fetch_grocery_density(community.center_lat, community.center_lng, radius_km=1.2)
        night_activity_index = fetch_night_activity_index(
            community.center_lat, community.center_lng, radius_km=1.5
        )
        noise_avg_db, noise_p90_db = fetch_noise_proxy(community.center_lat, community.center_lng)

    crime_rate = fetch_crime_rate_per_100k(community.city)

    payload: dict = {
        "updated_at": datetime.utcnow(),
        "grocery_density_per_km2": grocery_density,
        "crime_rate_per_100k": crime_rate,
        "night_activity_index": None,
        "noise_avg_db": noise_avg_db,
        "noise_p90_db": noise_p90_db,
        "overall_confidence": 0.5,
        "details_json": "{}",
    }
    if match:
        payload.update(
            {
                "median_rent": _to_float(match.get("median_rent")),
                "rent_2b2b": _to_float(match.get("rent_2b2b")),
                "rent_1b1b": _to_float(match.get("rent_1b1b")),
                "avg_sqft": _to_float(match.get("avg_sqft")),
                "rent_trend_12m_pct": _to_float(match.get("rent_trend_12m_pct")),
                "overall_confidence": 0.7,
            }
        )
    if night_activity_index is not None:
        payload["night_activity_index"] = night_activity_index

    required_keys = [
        "median_rent",
        "grocery_density_per_km2",
        "crime_rate_per_100k",
        "rent_trend_12m_pct",
        "night_activity_index",
        "noise_avg_db",
    ]
    available = sum(1 for key in required_keys if payload.get(key) is not None)
    payload["overall_confidence"] = round(available / len(required_keys), 2)

    payload["details_json"] = json.dumps(
        {
            "sources": {
                "zori_csv": bool(match),
                "overpass_grocery": grocery_density is not None,
                "overpass_night_activity": night_activity_index is not None,
                "overpass_noise": noise_avg_db is not None,
                "irvine_crime": crime_rate is not None,
            }
        },
        ensure_ascii=True,
    )

    metrics = crud.upsert_metrics(db, community_id, payload)
    score_input = {
        "median_rent": metrics.median_rent,
        "commute_minutes": None,
        "grocery_density_per_km2": metrics.grocery_density_per_km2,
        "crime_rate_per_100k": metrics.crime_rate_per_100k,
        "rent_trend_12m_pct": metrics.rent_trend_12m_pct,
        "noise_avg_db": metrics.noise_avg_db,
        "night_activity_index": metrics.night_activity_index,
        "review_signal_score": None,
    }
    scores = compute_dimension_scores(score_input)
    for dimension, value in scores.items():
        crud.upsert_dimension_score(
            db=db,
            community_id=community_id,
            dimension=dimension,
            score_0_100=value,
            summary=f"{dimension} score auto-generated by ingest pipeline",
            details=score_input,
            data_origin="api",
        )


def _to_float(value: str | None) -> float | None:
    if value in (None, ""):
        return None
    try:
        return float(value)
    except ValueError:
        return None
